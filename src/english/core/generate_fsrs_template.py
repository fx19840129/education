#!/usr/bin/env python3
"""
FSRSæ¨¡æ¿ç”Ÿæˆå™¨ - ç‹¬ç«‹å·¥å…·è„šæœ¬
åŒ…å«FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿ç”Ÿæˆã€æ ‡å‡†æ ¼å¼è½¬æ¢å’Œæ³¨è§£æ˜¾ç¤ºåŠŸèƒ½
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(project_root))

# å¯¼å…¥ç»Ÿä¸€AIå®¢æˆ·ç«¯
from src.shared.ai_framework.unified_ai_client import UnifiedAIClient, AIModel

# å¯¼å…¥æç¤ºè¯ç”Ÿæˆå™¨
from src.english.utils.ai_prompt_builder import EnglishLearningPromptGenerator


class FSRSTemplateGenerator:
    """FSRSæ¨¡æ¿ç”Ÿæˆå™¨ - ç‹¬ç«‹å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–FSRSæ¨¡æ¿ç”Ÿæˆå™¨"""
        self.prompt_generator = EnglishLearningPromptGenerator()
        self.ai_client = UnifiedAIClient(default_model=AIModel.GLM_45)
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»AIå“åº”å†…å®¹ä¸­æå–JSONå¯¹è±¡"""
        if not content:
            return None
            
        # æ–¹æ³•1: æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´çš„JSONå—ï¼ˆmarkdownæ ¼å¼ï¼‰
        json_start = content.rfind('```json')
        if json_start != -1:
            json_start = content.find('{', json_start)
            json_end = content.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                potential_json = content[json_start:json_end]
                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
                try:
                    import json
                    json.loads(potential_json)
                    print(f"âœ… ä»markdownä»£ç å—ä¸­æå–åˆ°æœ‰æ•ˆJSON")
                    return potential_json
                except:
                    pass
        
        # æ–¹æ³•2: æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}çš„å†…å®¹
        first_brace = content.find('{')
        last_brace = content.rfind('}')
        if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
            potential_json = content[first_brace:last_brace + 1]
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆJSON
            try:
                import json
                json.loads(potential_json)
                print(f"âœ… ä»å†…å®¹ä¸­æå–åˆ°æœ‰æ•ˆJSON (é•¿åº¦: {len(potential_json)} å­—ç¬¦)")
                return potential_json
            except Exception as e:
                print(f"âš ï¸ JSONéªŒè¯å¤±è´¥: {e}")
                pass
        
        # æ–¹æ³•3: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾JSONç»“æ„
        import re
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, content, re.DOTALL)
        for match in reversed(matches):  # ä»æœ€åä¸€ä¸ªåŒ¹é…å¼€å§‹å°è¯•
            try:
                import json
                json.loads(match)
                print(f"âœ… é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå–åˆ°æœ‰æ•ˆJSON")
                return match
            except:
                continue
        
        print(f"âŒ æ— æ³•ä»å†…å®¹ä¸­æå–æœ‰æ•ˆçš„JSONå¯¹è±¡")
        return None

    def convert_to_fsrs_standard_format(self, template: Dict) -> Dict:
        """å°†FSRSæ¨¡æ¿è½¬æ¢æˆFSRSæ ‡å‡†æ ¼å¼çš„JSON
        
        Args:
            template (Dict): ç”Ÿæˆçš„FSRSæ¨¡æ¿
            
        Returns:
            Dict: FSRSæ ‡å‡†æ ¼å¼çš„æ•°æ®ç»“æ„
        """
        print(f"\nğŸ”„ æ­£åœ¨è½¬æ¢ä¸ºFSRSæ ‡å‡†æ ¼å¼...")
        
        try:
            # ä»æ¨¡æ¿ä¸­æå–å…³é”®ä¿¡æ¯
            fsrs_template = template.get('fsrs_template', template)
            metadata = fsrs_template.get('metadata', {})
            fsrs_params = fsrs_template.get('fsrs_initial_parameters', {})
            daily_guidelines = fsrs_template.get('daily_planning_guidelines', {})
            word_categories = fsrs_template.get('word_categories', {})
            
            # æ„å»ºFSRSæ ‡å‡†æ ¼å¼
            fsrs_standard = {
                "scheduler_config": {
                    "parameters": [
                        0.2172, 1.1771, 3.2602, 16.1507, 7.0114, 0.57, 2.0966, 0.0069, 1.5261, 0.112,
                        1.0178, 1.849, 0.1133, 0.3127, 2.2934, 0.2191, 3.0004, 0.7536, 0.3332, 0.1437, 0.2
                    ],
                    "desired_retention": 0.9,
                    "learning_steps": [1, 10],  # åˆ†é’Ÿ
                    "relearning_steps": [10],   # åˆ†é’Ÿ
                    "maximum_interval": int(fsrs_params.get('default_ease', 2.0) * 365),  # åŸºäºeaseè®¡ç®—æœ€å¤§é—´éš”
                    "enable_fuzzing": True
                },
                "cards": [],  # ç©ºçš„å¡ç‰‡åˆ—è¡¨ï¼Œå°†ç”±å…·ä½“è¯æ±‡å¡«å……
                "learning_plan_metadata": {
                    "total_study_days": metadata.get('total_study_days', 30),
                    "daily_learning_minutes_target": metadata.get('daily_learning_minutes_target', 30),
                    "total_words_in_library": metadata.get('total_words_in_library', 0),
                    "total_morphology_units_in_library": metadata.get('total_morphology_units_in_library', 0),
                    "total_syntax_units_in_library": metadata.get('total_syntax_units_in_library', 0),
                    "estimated_avg_word_rotations_per_cycle": metadata.get('estimated_avg_word_rotations_per_cycle', 2.0),
                    "learning_efficiency_estimate": metadata.get('learning_efficiency_estimate', 1.0),
                    "review_efficiency_estimate": metadata.get('review_efficiency_estimate', 0.6),
                    "morphology_practice_time_estimate": metadata.get('morphology_practice_time_estimate', 4),
                    "syntax_practice_time_estimate": metadata.get('syntax_practice_time_estimate', 8)
                },
                "daily_targets": {
                    "avg_new_words_per_day": daily_guidelines.get('avg_new_words_per_day', 8),
                    "avg_review_words_per_day": daily_guidelines.get('avg_review_words_per_day', 8),
                    "avg_new_morphology_units_per_day": daily_guidelines.get('avg_new_morphology_units_per_day', 1),
                    "avg_review_morphology_units_per_day": daily_guidelines.get('avg_review_morphology_units_per_day', 1),
                    "avg_new_syntax_units_per_day": daily_guidelines.get('avg_new_syntax_units_per_day', 1),
                    "avg_review_syntax_units_per_day": daily_guidelines.get('avg_review_syntax_units_per_day', 1),
                    "suggested_morphology_practice_minutes_per_day": daily_guidelines.get('suggested_morphology_practice_minutes_per_day', 4),
                    "suggested_syntax_practice_minutes_per_day": daily_guidelines.get('suggested_syntax_practice_minutes_per_day', 8)
                },
                "word_categories": word_categories,
                "card_template": {
                    "id": "PLACEHOLDER_ID",
                    "text": "PLACEHOLDER_TEXT", 
                    "category": "core_functional",  # core_functional | connectors_relational | auxiliary_supplemental | morphology | syntax
                    "part_of_speech": "noun",  # å…·ä½“è¯æ€§
                    "due": "2024-01-01T00:00:00Z",  # UTCæ—¶é—´
                    "stability": 1.0,  # FSRSç¨³å®šæ€§å‚æ•°
                    "difficulty": 5.0,  # FSRSéš¾åº¦å‚æ•°
                    "elapsed_days": 0,  # ç»è¿‡å¤©æ•°
                    "scheduled_days": int(fsrs_params.get('new_word_first_review_interval_days', 0.3) * 24 * 60),  # è½¬æ¢ä¸ºåˆ†é’Ÿ
                    "reps": 0,  # å¤ä¹ æ¬¡æ•°
                    "lapses": 0,  # é—å¿˜æ¬¡æ•°
                    "state": 1,  # 1=Learning, 2=Review, 3=Relearning
                    "last_review": None,  # æœ€åå¤ä¹ æ—¶é—´
                    "review_logs": []  # å¤ä¹ å†å²
                },
                "review_rating_guide": {
                    "1": "Again - å®Œå…¨å¿˜è®°",
                    "2": "Hard - å›°éš¾è®°èµ·",
                    "3": "Good - çŠ¹è±«åè®°èµ·", 
                    "4": "Easy - è½»æ¾è®°èµ·"
                },
                "implementation_notes": daily_guidelines.get('notes_for_fsrs_implementation', 
                    "For FSRS implementation: Use scheduler_config to initialize FSRS scheduler, create cards based on card_template, and follow daily_targets for content generation."),
                "generated_at": datetime.now().isoformat(),
                "format_version": "1.0"
            }
            
            print(f"âœ… æˆåŠŸè½¬æ¢ä¸ºFSRSæ ‡å‡†æ ¼å¼")
            print(f"   è°ƒåº¦å™¨å‚æ•°: {len(fsrs_standard['scheduler_config']['parameters'])}ä¸ª")
            print(f"   å­¦ä¹ æ­¥éª¤: {fsrs_standard['scheduler_config']['learning_steps']}")
            print(f"   å¤ä¹ æ­¥éª¤: {fsrs_standard['scheduler_config']['relearning_steps']}")
            print(f"   æœ€å¤§é—´éš”: {fsrs_standard['scheduler_config']['maximum_interval']}å¤©")
            print(f"   æ¯æ—¥æ–°è¯ç›®æ ‡: {fsrs_standard['daily_targets']['avg_new_words_per_day']}ä¸ª")
            print(f"   æ¯æ—¥å¤ä¹ ç›®æ ‡: {fsrs_standard['daily_targets']['avg_review_words_per_day']}ä¸ª")
            
            return fsrs_standard
            
        except Exception as e:
            print(f"âŒ è½¬æ¢ä¸ºFSRSæ ‡å‡†æ ¼å¼å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"error": f"è½¬æ¢å¤±è´¥: {e}"}

    def print_fsrs_template_with_annotations(self, full_template: Dict):
        """æ‰“å°å¸¦æœ‰ä¸­æ–‡æ³¨è§£çš„FSRSæ¨¡æ¿å†…å®¹"""
        import json
        
        template = full_template.get("fsrs_template", {})
        
        # æ˜¾ç¤ºç®€åŒ–çš„å¸¦æ³¨è§£ç‰ˆæœ¬
        print("ğŸ“Š FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿ - å­—æ®µè¯´æ˜")
        print("=" * 50)
        
        # å…ƒæ•°æ®ä¿¡æ¯
        if "metadata" in template:
            print("\nğŸ“Š å…ƒæ•°æ®ä¿¡æ¯ (metadata):")
            metadata = template["metadata"]
            print(f"  â€¢ total_study_days: {metadata.get('total_study_days', 'N/A')} // æ€»å­¦ä¹ å‘¨æœŸå¤©æ•°")
            print(f"  â€¢ daily_learning_minutes_target: {metadata.get('daily_learning_minutes_target', 'N/A')} // æ¯æ—¥å­¦ä¹ æ€»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
            print(f"  â€¢ total_words_in_library: {metadata.get('total_words_in_library', 'N/A')} // è¯åº“æ€»è¯æ•°")
            print(f"  â€¢ total_morphology_units_in_library: {metadata.get('total_morphology_units_in_library', 'N/A')} // è¯æ³•åº“æ€»å•ä½æ•°")
            print(f"  â€¢ total_syntax_units_in_library: {metadata.get('total_syntax_units_in_library', 'N/A')} // å¥æ³•åº“æ€»å•ä½æ•°")
            print(f"  â€¢ estimated_avg_word_rotations_per_cycle: {metadata.get('estimated_avg_word_rotations_per_cycle', 'N/A')} // æ¯ä¸ªå•è¯åœ¨å‘¨æœŸå†…çš„å¹³å‡å¤ä¹ æ¬¡æ•°")
            print(f"  â€¢ learning_efficiency_estimate: {metadata.get('learning_efficiency_estimate', 'N/A')} // å­¦ä¹ æ–°å•è¯ä¼°ç®—æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
            print(f"  â€¢ review_efficiency_estimate: {metadata.get('review_efficiency_estimate', 'N/A')} // å¤ä¹ å•è¯ä¼°ç®—æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
            print(f"  â€¢ morphology_practice_time_estimate: {metadata.get('morphology_practice_time_estimate', 'N/A')} // è¯æ³•ç»ƒä¹ ä¼°ç®—æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
            print(f"  â€¢ syntax_practice_time_estimate: {metadata.get('syntax_practice_time_estimate', 'N/A')} // å¥æ³•ç»ƒä¹ ä¼°ç®—æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
        
        # è¯æ€§åˆ†ç±»
        if "word_categories" in template:
            print("\nğŸ·ï¸ è¯æ€§åˆ†ç±»å®šä¹‰ (word_categories):")
            categories = template["word_categories"]
            print(f"  â€¢ core_functional: {categories.get('core_functional', [])} // æ ¸å¿ƒåŠŸèƒ½è¯ï¼ˆå¥å­éª¨æ¶ï¼Œä¸»è¦åŠ¨ä½œå’Œå¯¹è±¡ï¼‰")
            print(f"  â€¢ connectors_relational: {categories.get('connectors_relational', [])} // è¿æ¥ä¸å…³ç³»è¯ï¼ˆè¿æ¥ã€ä¿®é¥°ã€é™å®šã€è¡¨è¾¾å…³ç³»ï¼‰")
            print(f"  â€¢ auxiliary_supplemental: {categories.get('auxiliary_supplemental', [])} // è¾…åŠ©ä¸è¡¥å……è¯ï¼ˆè¯­æ°”ã€æƒ…æ„Ÿã€è¾…åŠ©åŠŸèƒ½ï¼‰")
        
        # FSRSå‚æ•°
        if "fsrs_initial_parameters" in template:
            print("\nğŸ¯ FSRSç®—æ³•åˆå§‹å‚æ•° (fsrs_initial_parameters):")
            fsrs_params = template["fsrs_initial_parameters"]
            print(f"  â€¢ default_ease: {fsrs_params.get('default_ease', 'N/A')} // é»˜è®¤éš¾åº¦ç³»æ•°ï¼ˆç”±æ¨¡å‹æ ¹æ®ç›®æ ‡å¤ä¹ æ¬¡æ•°å’Œå‘¨æœŸè®¡ç®—ï¼‰")
            print(f"  â€¢ new_word_first_review_interval_days: {fsrs_params.get('new_word_first_review_interval_days', 'N/A')} // æ–°å•è¯é¦–æ¬¡å¤ä¹ é—´éš”å¤©æ•°ï¼ˆç”±æ¨¡å‹å»ºè®®ï¼‰")
            print(f"  â€¢ morphology_first_review_interval_days: {fsrs_params.get('morphology_first_review_interval_days', 'N/A')} // è¯æ³•é¦–æ¬¡å¤ä¹ é—´éš”å¤©æ•°ï¼ˆç”±æ¨¡å‹å»ºè®®ï¼‰")
            print(f"  â€¢ syntax_first_review_interval_days: {fsrs_params.get('syntax_first_review_interval_days', 'N/A')} // å¥æ³•é¦–æ¬¡å¤ä¹ é—´éš”å¤©æ•°ï¼ˆç”±æ¨¡å‹å»ºè®®ï¼‰")
        
        # æ¯æ—¥è§„åˆ’æŒ‡å¯¼
        if "daily_planning_guidelines" in template:
            print("\nğŸ“… æ¯æ—¥å­¦ä¹ é‡å’Œåˆ†å¸ƒçš„å®è§‚æŒ‡å¯¼ (daily_planning_guidelines):")
            guidelines = template["daily_planning_guidelines"]
            print(f"  â€¢ avg_new_words_per_day: {guidelines.get('avg_new_words_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å­¦ä¹ çš„æ–°å•è¯æ€»æ•°")
            print(f"  â€¢ avg_review_words_per_day: {guidelines.get('avg_review_words_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å¤ä¹ çš„å•è¯æ€»æ•°")
            print(f"  â€¢ avg_new_morphology_units_per_day: {guidelines.get('avg_new_morphology_units_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å­¦ä¹ çš„æ–°è¯æ³•å•ä½æ•°")
            print(f"  â€¢ avg_review_morphology_units_per_day: {guidelines.get('avg_review_morphology_units_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å¤ä¹ çš„è¯æ³•å•ä½æ•°")
            print(f"  â€¢ avg_new_syntax_units_per_day: {guidelines.get('avg_new_syntax_units_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å­¦ä¹ çš„æ–°å¥æ³•å•ä½æ•°")
            print(f"  â€¢ avg_review_syntax_units_per_day: {guidelines.get('avg_review_syntax_units_per_day', 'N/A')} // æ•´ä¸ªå‘¨æœŸå†…å¹³å‡æ¯å¤©å¤ä¹ çš„å¥æ³•å•ä½æ•°")
            print(f"  â€¢ morphology_rotation_cycles_per_day: {guidelines.get('morphology_rotation_cycles_per_day', 'N/A')} // è¯æ³•å•ä½æ¯æ—¥è½®è½¬æ¬¡æ•°")
            print(f"  â€¢ syntax_rotation_cycles_per_day: {guidelines.get('syntax_rotation_cycles_per_day', 'N/A')} // å¥æ³•å•ä½æ¯æ—¥è½®è½¬æ¬¡æ•°")
            
            if "new_words_composition_guideline" in guidelines:
                print("  â€¢ new_words_composition_guideline: // æ–°å­¦å•è¯çš„è¯æ€§åˆ†å¸ƒæŒ‡ç¤ºï¼ˆæŒ‰ç™¾åˆ†æ¯”ï¼‰")
                composition = guidelines["new_words_composition_guideline"]
                print(f"    - core_functional_percentage: {composition.get('core_functional_percentage', 'N/A')}% // æ ¸å¿ƒåŠŸèƒ½è¯ï¼ˆåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ï¼‰çš„æ€»ç™¾åˆ†æ¯”")
                print(f"    - connectors_relational_percentage: {composition.get('connectors_relational_percentage', 'N/A')}% // è¿æ¥ä¸å…³ç³»è¯çš„æ€»ç™¾åˆ†æ¯”")
                print(f"    - auxiliary_supplemental_percentage: {composition.get('auxiliary_supplemental_percentage', 'N/A')}% // è¾…åŠ©ä¸è¡¥å……è¯çš„æ€»ç™¾åˆ†æ¯”")
            
            print(f"  â€¢ suggested_morphology_practice_minutes_per_day: {guidelines.get('suggested_morphology_practice_minutes_per_day', 'N/A')} // æ¯æ—¥å»ºè®®çš„è¯æ³•ç»ƒä¹ åˆ†é’Ÿæ•°")
            print(f"  â€¢ suggested_syntax_practice_minutes_per_day: {guidelines.get('suggested_syntax_practice_minutes_per_day', 'N/A')} // æ¯æ—¥å»ºè®®çš„å¥æ³•ç»ƒä¹ åˆ†é’Ÿæ•°")
            print(f"  â€¢ notes_for_fsrs_implementation: // å…³äºå¦‚ä½•ä½¿ç”¨æ­¤æ¨¡æ¿å’ŒFSRSå·¥å…·çš„æç¤º")
            print(f"    \"{guidelines.get('notes_for_fsrs_implementation', 'N/A')}\"")
        
        # å¤ä¹ é¡¹ç¤ºä¾‹
        if "example_review_item_structure_for_fsrs" in template:
            print("\nğŸ“ å¤ä¹ é¡¹çš„FSRSè¾“å…¥æ ¼å¼ç¤ºä¾‹ (example_review_item_structure_for_fsrs):")
            example = template["example_review_item_structure_for_fsrs"]
            print(f"  â€¢ id: \"{example.get('id', 'PLACEHOLDER_ID')}\" // é¡¹ç›®å”¯ä¸€æ ‡è¯†")
            print(f"  â€¢ text: \"{example.get('text', 'PLACEHOLDER_TEXT')}\" // å•è¯æ–‡æœ¬")
            print(f"  â€¢ category: \"{example.get('category', '...')}\" // å•è¯ç±»åˆ«")
            print(f"  â€¢ part_of_speech: \"{example.get('part_of_speech', '...')}\" // è¯æ€§")
            print(f"  â€¢ initial_interval_days: \"{example.get('initial_interval_days', '1')}\" // åˆå§‹å¤ä¹ é—´éš”å¤©æ•°ï¼ˆå»ºè®®å€¼ï¼‰")
            print(f"  â€¢ status: \"{example.get('status', 'review')}\" // å¤ä¹ çŠ¶æ€")
        
        print("\n" + "=" * 50)
        print("ğŸ“„ å®Œæ•´JSONç»“æ„:")
        print(json.dumps(full_template, ensure_ascii=False, indent=2))

    def generate_fsrs_template(self, stage: str, days: int, minutes: int, 
                               learning_efficiency: float = 1.0, review_efficiency: float = 0.6,
                               morphology_time: int = 4, syntax_time: int = 8) -> Dict:
        """ç”ŸæˆFSRSç®—æ³•é€‚é…çš„å­¦ä¹ è®¡åˆ’æ¨¡æ¿"""
        print(f"\nğŸ”„ æ­£åœ¨ç”ŸæˆFSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿...")
        print(f"   å­¦ä¹ é˜¶æ®µ: {stage}")
        print(f"   å­¦ä¹ å‘¨æœŸ: {days} å¤©")
        print(f"   æ¯æ—¥æ—¶é—´: {minutes} åˆ†é’Ÿ")
        print(f"   æ•ˆç‡å‚æ•°: å­¦ä¹ {learning_efficiency}åˆ†é’Ÿ/è¯, å¤ä¹ {review_efficiency}åˆ†é’Ÿ/è¯, è¯æ³•{morphology_time}åˆ†é’Ÿ/æ¬¡, å¥æ³•{syntax_time}åˆ†é’Ÿ/æ¬¡")
        
        # è·å–è¯æ€§åˆ†å¸ƒæ•°æ®
        vocab_selector = self.prompt_generator.vocab_selector
        pos_distribution = vocab_selector.get_stage_pos_words_summary(stage)
        morphology_total = 13
        syntax_total = 16
        
        # ç”ŸæˆFSRSæ¨¡æ¿çš„AIæç¤ºè¯
        prompt = self.prompt_generator.generate_fsrs_template_prompt(
            days, minutes, pos_distribution, morphology_total, syntax_total, stage,
            learning_efficiency, review_efficiency, morphology_time, syntax_time
        )
        
        print("=" * 80)
        print("ğŸ“ å®Œæ•´FSRSæ¨¡æ¿æç¤ºè¯:")
        print("=" * 80)
        print(prompt)
        print("=" * 80)
        
        # è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå­¦ä¹ è®¡åˆ’æ¨¡æ¿
        print(f"\nğŸ¤– æ­£åœ¨è°ƒç”¨AIæ¨¡å‹ç”ŸæˆFSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿...")
        start_time = time.time()
        
        try:
            print(f"ğŸ¯ å¼€å§‹è°ƒç”¨AIç”ŸæˆFSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿")
            print(f"   å­¦ä¹ é˜¶æ®µ: {stage}")
            print(f"   å­¦ä¹ å‘¨æœŸ: {days}å¤©")
            print(f"   æ¯æ—¥æ—¶é—´: {minutes}åˆ†é’Ÿ")
            print(f"ğŸ”§ ä½¿ç”¨ç»Ÿä¸€AIå®¢æˆ·ç«¯è°ƒç”¨")
            
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    print(f"ğŸ”„ ç¬¬ {attempt + 1} æ¬¡å°è¯•è°ƒç”¨AIæ¨¡å‹...")
                    
                    # ä½¿ç”¨éæµå¼è¾“å‡ºç”Ÿæˆå­¦ä¹ è®¡åˆ’æ¨¡æ¿
                    response = self.ai_client.generate_content(
                        prompt=prompt,
                        temperature=0.7,
                        max_tokens=5000,  # FSRSæ¨¡æ¿JSONå“åº”çº¦1400å­—ç¬¦ï¼Œ3000 tokensæä¾›å……è¶³ç¼“å†²
                        model=AIModel.GLM_45,
                        timeout=120.0  # è®¾ç½®2åˆ†é’Ÿè¶…æ—¶
                    )
                    
                    response_time = time.time() - start_time
                    
                    # æ£€æŸ¥æ˜¯å¦æˆåŠŸä¸”æœ‰å†…å®¹
                    if response.success and response.content and response.content.strip():
                        print(f"âœ… AIç”ŸæˆæˆåŠŸ! (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                        print(f"âœ… AIç”ŸæˆæˆåŠŸ!")
                        print(f"   æ¨¡å‹: {response.model}")
                        print(f"   å“åº”æ—¶é—´: {response_time:.2f}ç§’")
                        print(f"   ä½¿ç”¨æƒ…å†µ: {response.usage}")
                        print(f"   å®ŒæˆåŸå› : {response.finish_reason}")
                        
                        print(f"\nğŸ“‹ AIç”Ÿæˆçš„FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿:")
                        print("=" * 80)
                        print(response.content[:1000] + "..." if len(response.content) > 1000 else response.content)
                        print("=" * 80)
                
                        # å°è¯•è§£æAIè¿”å›çš„JSON
                        try:
                            import json
                            # ä½¿ç”¨å¥å£®çš„JSONæå–æ–¹æ³•
                            json_content = self._extract_json_from_content(response.content)
                            if json_content:
                                template = json.loads(json_content)
                            else:
                                # å¦‚æœæå–å¤±è´¥ï¼Œå°è¯•ç›´æ¥è§£æ
                                template = json.loads(response.content)
                            print(f"âœ… æˆåŠŸè§£æAIè¿”å›çš„FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿JSON")
                            
                            # ä¿å­˜å­¦ä¹ è®¡åˆ’æ¨¡æ¿
                            template_id = datetime.now().strftime("%Y%m%d_%H%M%S")
                            output_file = Path("outputs/english/plans/fsrs_templates") / f"fsrs_template_{template_id}.json"
                            output_file.parent.mkdir(parents=True, exist_ok=True)
                            
                            # æ„å»ºå®Œæ•´çš„å­¦ä¹ è®¡åˆ’æ¨¡æ¿æ•°æ®
                            full_template = {
                                "id": template_id,
                                "type": "fsrs_learning_template",
                                "metadata": {
                                    "stage": stage,
                                    "days": days,
                                    "minutes_per_day": minutes,
                                    "ai_model": response.model,
                                    "generated_at": datetime.now().isoformat(),
                                    "ai_response_time": response_time,
                                    "ai_usage": response.usage,
                                    "retry_count": attempt + 1
                                },
                                "fsrs_template": template
                            }
                            
                            with open(output_file, 'w', encoding='utf-8') as f:
                                json.dump(full_template, f, ensure_ascii=False, indent=2)
                            
                            print(f"ğŸ’¾ FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿å·²ä¿å­˜åˆ°: {output_file}")
                            print(f"ğŸ“‹ æ¨¡æ¿ID: {template_id}")
                            
                            # æ˜¾ç¤ºæ¨¡æ¿æ‘˜è¦
                            if "metadata" in template:
                                metadata = template["metadata"]
                                print(f"ğŸ“‹ æ€»å­¦ä¹ å¤©æ•°: {metadata.get('total_study_days', 'æœªçŸ¥')}å¤©")
                                print(f"ğŸ“‹ æ¯æ—¥ç›®æ ‡æ—¶é—´: {metadata.get('daily_learning_minutes_target', 'æœªçŸ¥')}åˆ†é’Ÿ")
                                print(f"ğŸ“‹ è¯åº“æ€»æ•°: {metadata.get('total_words_in_library', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ é¢„è®¡è½®è½¬æ¬¡æ•°: {metadata.get('estimated_avg_word_rotations_per_cycle', 'æœªçŸ¥')}")
                            
                            if "daily_planning_guidelines" in template:
                                guidelines = template["daily_planning_guidelines"]
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥æ–°è¯: {guidelines.get('avg_new_words_per_day', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥å¤ä¹ : {guidelines.get('avg_review_words_per_day', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥æ–°è¯æ³•: {guidelines.get('avg_new_morphology_units_per_day', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥å¤ä¹ è¯æ³•: {guidelines.get('avg_review_morphology_units_per_day', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥æ–°å¥æ³•: {guidelines.get('avg_new_syntax_units_per_day', 'æœªçŸ¥')}ä¸ª")
                                print(f"ğŸ“‹ å¹³å‡æ¯æ—¥å¤ä¹ å¥æ³•: {guidelines.get('avg_review_syntax_units_per_day', 'æœªçŸ¥')}ä¸ª")
                            
                            print(f"\nğŸ“„ å®Œæ•´FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿å†…å®¹ï¼ˆå¸¦å­—æ®µæ³¨è§£ï¼‰:")
                            print("=" * 100)
                            self.print_fsrs_template_with_annotations(full_template)
                            print("=" * 100)
                            
                            # è½¬æ¢ä¸ºFSRSæ ‡å‡†æ ¼å¼å¹¶ä¿å­˜
                            fsrs_standard = self.convert_to_fsrs_standard_format(full_template)
                            if "error" not in fsrs_standard:
                                # ä¿å­˜FSRSæ ‡å‡†æ ¼å¼æ–‡ä»¶
                                fsrs_output_file = Path("outputs/english/plans/fsrs_standard") / f"fsrs_standard_{template_id}.json"
                                with open(fsrs_output_file, 'w', encoding='utf-8') as f:
                                    json.dump(fsrs_standard, f, ensure_ascii=False, indent=2)
                                print(f"ğŸ’¾ FSRSæ ‡å‡†æ ¼å¼å·²ä¿å­˜åˆ°: {fsrs_output_file}")
                                
                                # åœ¨è¿”å›çš„æ•°æ®ä¸­æ·»åŠ FSRSæ ‡å‡†æ ¼å¼
                                full_template["fsrs_standard_format"] = fsrs_standard
                            
                            return full_template
                            
                        except json.JSONDecodeError as e:
                            print(f"âŒ è§£æAIè¿”å›çš„JSONå¤±è´¥: {e}")
                            print(f"ğŸ” åŸå§‹å†…å®¹: {response.content[:500]}...")
                            
                            # ä¿å­˜å¤±è´¥çš„å“åº”ç”¨äºè°ƒè¯•
                            template_id = datetime.now().strftime("%Y%m%d_%H%M%S")
                            output_file = Path("outputs/english/plans/fsrs_templates") / f"fsrs_template_error_{template_id}.json"
                            output_file.parent.mkdir(parents=True, exist_ok=True)
                            
                            full_template = {
                                "id": template_id,
                                "type": "fsrs_learning_template",
                                "metadata": {
                                    "stage": stage,
                                    "days": days,
                                    "minutes_per_day": minutes,
                                    "ai_model": response.model,
                                    "generated_at": datetime.now().isoformat(),
                                    "ai_response_time": response_time,
                                    "ai_usage": response.usage,
                                    "parse_error": str(e)
                                },
                                "fsrs_template": None,
                                "raw_content": response.content
                            }
                            
                            with open(output_file, 'w', encoding='utf-8') as f:
                                json.dump(full_template, f, ensure_ascii=False, indent=2)
                            
                            print(f"ğŸ’¾ å¤±è´¥çš„å“åº”å·²ä¿å­˜åˆ°: {output_file}")
                            
                            # å¦‚æœè¿™ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»§ç»­é‡è¯•
                            if attempt < max_retries - 1:
                                print(f"ğŸ”„ å°†è¿›è¡Œç¬¬ {attempt + 2} æ¬¡å°è¯•...")
                                continue
                            else:
                                return full_template
                    else:
                        print(f"âŒ AIç”Ÿæˆå¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                        print(f"   æˆåŠŸçŠ¶æ€: {response.success}")
                        print(f"   å†…å®¹é•¿åº¦: {len(response.content) if response.content else 0}")
                        print(f"   é”™è¯¯ä¿¡æ¯: {response.error_message}")
                        
                        if attempt < max_retries - 1:
                            print(f"ğŸ”„ å°†è¿›è¡Œç¬¬ {attempt + 2} æ¬¡å°è¯•...")
                            continue
                        else:
                            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                            return {
                                "error": "AIç”Ÿæˆå¤±è´¥",
                                "details": {
                                    "success": response.success,
                                    "error_message": response.error_message,
                                    "attempts": max_retries
                                }
                            }
                            
                except Exception as e:
                    print(f"âŒ è°ƒç”¨AIæ¨¡å‹æ—¶å‘ç”Ÿå¼‚å¸¸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•): {e}")
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
                        time.sleep(2)
                        continue
                    else:
                        # å¼‚å¸¸å¤„ç†çš„æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        return {
                            "error": "AIè°ƒç”¨å¼‚å¸¸",
                            "details": {
                                "exception": str(e),
                                "attempts": max_retries
                            }
                        }
            
            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
            return {
                "error": "AIç”Ÿæˆå¤±è´¥",
                "details": {
                    "attempts": max_retries
                }
            }
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå­¦ä¹ è®¡åˆ’æ¨¡æ¿æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                "error": "ç”Ÿæˆå­¦ä¹ è®¡åˆ’æ¨¡æ¿å¼‚å¸¸",
                "details": {
                    "exception": str(e)
                }
            }

    def run_interactive(self):
        """è¿è¡Œäº¤äº’å¼FSRSæ¨¡æ¿ç”Ÿæˆ"""
        try:
            print("ğŸ“ FSRSæ¨¡æ¿ç”Ÿæˆå™¨")
            print("=" * 50)
            
            print("\nğŸ“š FSRSç®—æ³•é€‚é…å­¦ä¹ è®¡åˆ’æ¨¡æ¿ç”Ÿæˆ")
            print("æ­£åœ¨å¯åŠ¨FSRSæ¨¡æ¿ç”ŸæˆåŠŸèƒ½...")
            
            print("\nğŸ¯ FSRSç®—æ³•é€‚é…å­¦ä¹ è®¡åˆ’æ¨¡æ¿ç”Ÿæˆ")
            print("-" * 30)
            
            # é€‰æ‹©å­¦ä¹ é˜¶æ®µ
            print("\nğŸ“š è¯·é€‰æ‹©å­¦ä¹ é˜¶æ®µ:")
            stage_options = self.prompt_generator.get_stage_options()
            
            for i, stage in enumerate(stage_options, 1):
                stage_name = stage.replace('### ', '').strip()
                print(f"{i}. {stage_name}")
            
            while True:
                try:
                    stage_choice = input(f"\nè¯·è¾“å…¥é€‰æ‹© (1-{len(stage_options)}): ").strip()
                    if stage_choice.isdigit():
                        stage_index = int(stage_choice) - 1
                        if 0 <= stage_index < len(stage_options):
                            selected_stage = stage_options[stage_index]
                            break
                    print(f"âŒ è¯·è¾“å…¥1åˆ°{len(stage_options)}ä¹‹é—´çš„æ•°å­—")
                except (ValueError, KeyboardInterrupt):
                    print("âŒ è¾“å…¥æ— æ•ˆï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
            
            # è¾“å…¥å­¦ä¹ å‘¨æœŸ
            while True:
                try:
                    days = int(input("ğŸ“… è¯·è¾“å…¥å­¦ä¹ å‘¨æœŸï¼ˆå¤©æ•°ï¼‰: ").strip())
                    if days > 0:
                        break
                    else:
                        print("âŒ å­¦ä¹ å‘¨æœŸå¿…é¡»å¤§äº0")
                except (ValueError, KeyboardInterrupt):
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    continue
            
            # è¾“å…¥æ¯æ—¥å­¦ä¹ æ—¶é—´
            while True:
                try:
                    minutes = int(input("â° è¯·è¾“å…¥æ¯æ—¥å­¦ä¹ æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰: ").strip())
                    if minutes > 0:
                        break
                    else:
                        print("âŒ å­¦ä¹ æ—¶é—´å¿…é¡»å¤§äº0")
                except (ValueError, KeyboardInterrupt):
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    continue
                    
                # è¯¢é—®æ˜¯å¦è‡ªå®šä¹‰æ•ˆç‡å‚æ•°
            print("\nğŸ”§ æ•ˆç‡å‚æ•°è®¾ç½®:")
            print("æ˜¯å¦ä½¿ç”¨é»˜è®¤æ•ˆç‡å‚æ•°ï¼Ÿ")
            print("ğŸ“Š é»˜è®¤å€¼: å­¦ä¹ æ•ˆç‡1.0åˆ†é’Ÿ/è¯, å¤ä¹ æ•ˆç‡0.6åˆ†é’Ÿ/è¯, è¯æ³•ç»ƒä¹ 4åˆ†é’Ÿ/æ¬¡, å¥æ³•ç»ƒä¹ 8åˆ†é’Ÿ/æ¬¡")
            
            use_default = input("ä½¿ç”¨é»˜è®¤å€¼ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
            
            if use_default in ['n', 'no', 'å¦']:
                # è‡ªå®šä¹‰æ•ˆç‡å‚æ•°
                try:
                    learning_efficiency = input("\nğŸ“š è¯·è¾“å…¥å­¦ä¹ æ–°è¯æ•ˆç‡ï¼ˆåˆ†é’Ÿ/è¯ï¼Œé»˜è®¤1.0ï¼‰: ").strip()
                    learning_efficiency = 1.0 if learning_efficiency == "" else float(learning_efficiency)
                    
                    review_efficiency = input("ğŸ”„ è¯·è¾“å…¥å¤ä¹ è¯æ±‡æ•ˆç‡ï¼ˆåˆ†é’Ÿ/è¯ï¼Œé»˜è®¤0.6ï¼‰: ").strip()
                    review_efficiency = 0.6 if review_efficiency == "" else float(review_efficiency)
                    
                    morphology_time = input("ğŸ“ è¯·è¾“å…¥è¯æ³•ç»ƒä¹ æ—¶é—´ï¼ˆåˆ†é’Ÿ/æ¬¡ï¼Œé»˜è®¤4ï¼‰: ").strip()
                    morphology_time = 4 if morphology_time == "" else int(morphology_time)
                    
                    syntax_time = input("ğŸ“– è¯·è¾“å…¥å¥æ³•ç»ƒä¹ æ—¶é—´ï¼ˆåˆ†é’Ÿ/æ¬¡ï¼Œé»˜è®¤8ï¼‰: ").strip()
                    syntax_time = 8 if syntax_time == "" else int(syntax_time)
                    
                except (ValueError, KeyboardInterrupt, Exception) as e:
                    print(f"âŒ è¾“å…¥é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                    learning_efficiency, review_efficiency, morphology_time, syntax_time = 1.0, 0.6, 4, 8
            else:
                # ä½¿ç”¨é»˜è®¤å€¼
                learning_efficiency, review_efficiency, morphology_time, syntax_time = 1.0, 0.6, 4, 8
                
            # ç”ŸæˆFSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿
            fsrs_template = self.generate_fsrs_template(
                selected_stage, days, minutes, 
                learning_efficiency, review_efficiency, morphology_time, syntax_time
            )
            
            if "error" not in fsrs_template:
                print("\nğŸ‰ FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿ç”Ÿæˆå®Œæˆ!")
            else:
                print(f"\nâŒ FSRSå­¦ä¹ è®¡åˆ’æ¨¡æ¿ç”Ÿæˆå¤±è´¥: {fsrs_template['error']}")
                
        except KeyboardInterrupt:
            print("\n\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    generator = FSRSTemplateGenerator()
    generator.run_interactive()


if __name__ == "__main__":
    main()
