#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„å•è¯æœåŠ¡
æä¾›å•è¯ç»Ÿè®¡åŠŸèƒ½ï¼Œä¸ä¾èµ–å¤æ‚çš„infrastructure
"""

import json
from pathlib import Path
from typing import Dict

class SimpleWordService:
    """ç®€åŒ–çš„å•è¯æœåŠ¡"""
    
    def __init__(self, config_dir: str = "src/english/config"):
        self.config_dir = Path(config_dir)
    
    def get_learning_resource_statistics(self, show_stats: bool = False) -> Dict:
        """èŽ·å–å­¦ä¹ èµ„æºç»Ÿè®¡ä¿¡æ¯ï¼ˆè¯æ±‡ã€è¯æ³•ã€å¥æ³•ï¼‰"""
        stats = {
            "words": {
                "elementary": 0,  # å°å­¦
                "junior_high": 0,  # åˆä¸­
                "high_school": 0,  # é«˜ä¸­
                "total": 0
            },
            "pos_distribution": {
                "elementary": {},  # å°å­¦è¯æ€§åˆ†å¸ƒ
                "junior_high": {},  # åˆä¸­è¯æ€§åˆ†å¸ƒ
                "high_school": {},  # é«˜ä¸­è¯æ€§åˆ†å¸ƒ
                "total": {}  # æ€»è®¡è¯æ€§åˆ†å¸ƒ
            },
            "morphology": {
                "elementary": 0,
                "junior_high": 0,
                "high_school": 0,
                "total": 0
            },
            "syntax": {
                "elementary": 0,
                "junior_high": 0,
                "high_school": 0,
                "total": 0
            }
        }
        
        try:
            # åŠ è½½è¯æ±‡ç»Ÿè®¡
            word_files = [
                ("elementary", "word_configs", "å°å­¦è‹±è¯­å•è¯.json"),
                ("junior_high", "word_configs", "åˆä¸­è‹±è¯­å•è¯.json"),
                ("high_school", "word_configs", "é«˜ä¸­è‹±è¯­å•è¯.json")
            ]
            
            for stage, config_dir, filename in word_files:
                file_path = self.config_dir / config_dir / filename
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        stats["words"][stage] = data.get("metadata", {}).get("word_count", 0)
                        # èŽ·å–è¯æ€§åˆ†å¸ƒ
                        pos_dist = data.get("metadata", {}).get("pos_distribution", {})
                        stats["pos_distribution"][stage] = pos_dist
            
            # ä½¿ç”¨è¯æ³•æœåŠ¡èŽ·å–è¯æ³•ç»Ÿè®¡
            from .morphology_service import MorphologyService
            morphology_service = MorphologyService(str(self.config_dir))
            stats["morphology"]["elementary"] = morphology_service.get_morphology_count("å°å­¦")
            stats["morphology"]["junior_high"] = morphology_service.get_morphology_count("åˆä¸­")
            stats["morphology"]["high_school"] = morphology_service.get_morphology_count("é«˜ä¸­")
            
            # ä½¿ç”¨å¥æ³•æœåŠ¡èŽ·å–å¥æ³•ç»Ÿè®¡
            from .syntax_service import SyntaxService
            syntax_service = SyntaxService(str(self.config_dir))
            stats["syntax"]["elementary"] = syntax_service.get_syntax_count("å°å­¦")
            stats["syntax"]["junior_high"] = syntax_service.get_syntax_count("åˆä¸­")
            stats["syntax"]["high_school"] = syntax_service.get_syntax_count("é«˜ä¸­")
            
            # è®¡ç®—æ€»è®¡
            stats["words"]["total"] = sum(stats["words"][stage] for stage in ["elementary", "junior_high", "high_school"])
            stats["morphology"]["total"] = sum(stats["morphology"][stage] for stage in ["elementary", "junior_high", "high_school"])
            stats["syntax"]["total"] = sum(stats["syntax"][stage] for stage in ["elementary", "junior_high", "high_school"])
            
            # è®¡ç®—æ€»è®¡è¯æ€§åˆ†å¸ƒ
            total_pos = {}
            for stage in ["elementary", "junior_high", "high_school"]:
                for pos, count in stats["pos_distribution"][stage].items():
                    total_pos[pos] = total_pos.get(pos, 0) + count
            stats["pos_distribution"]["total"] = total_pos
            
            if show_stats:
                print(f"ðŸ“Š å­¦ä¹ èµ„æºç»Ÿè®¡:")
                print(f"   è¯æ±‡:")
                print(f"     - å°å­¦: {stats['words']['elementary']}ä¸ª")
                print(f"     - åˆä¸­: {stats['words']['junior_high']}ä¸ª")
                print(f"     - é«˜ä¸­: {stats['words']['high_school']}ä¸ª")
                print(f"     - æ€»è®¡: {stats['words']['total']}ä¸ª")
                
                # æ‰“å°è¯æ€§åˆ†å¸ƒ
                self._print_pos_distribution(stats)
                
                print(f"   è¯æ³•:")
                print(f"     - å°å­¦: {stats['morphology']['elementary']}ä¸ª")
                print(f"     - åˆä¸­: {stats['morphology']['junior_high']}ä¸ª")
                print(f"     - é«˜ä¸­: {stats['morphology']['high_school']}ä¸ª")
                print(f"     - æ€»è®¡: {stats['morphology']['total']}ä¸ª")
                print(f"   å¥æ³•:")
                print(f"     - å°å­¦: {stats['syntax']['elementary']}ä¸ª")
                print(f"     - åˆä¸­: {stats['syntax']['junior_high']}ä¸ª")
                print(f"     - é«˜ä¸­: {stats['syntax']['high_school']}ä¸ª")
                print(f"     - æ€»è®¡: {stats['syntax']['total']}ä¸ª")
                print()
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å­¦ä¹ èµ„æºç»Ÿè®¡å¤±è´¥: {e}")
        
        return stats
    
    def _print_pos_distribution(self, stats: Dict) -> None:
        """æ‰“å°è¯æ€§åˆ†å¸ƒä¿¡æ¯"""
        # å®šä¹‰è¯æ€§æ˜ å°„ï¼ˆå°†å¤æ‚è¯æ€§æ˜ å°„åˆ°ç®€å•è¯æ€§ï¼‰
        pos_mapping = {
            "noun": "åè¯",
            "verb": "åŠ¨è¯", 
            "adjective": "å½¢å®¹è¯",
            "adverb": "å‰¯è¯",
            "preposition": "ä»‹è¯",
            "pronoun": "ä»£è¯",
            "conjunction": "è¿žè¯",
            "article": "å† è¯",
            "determiner": "é™å®šè¯",
            "interjection": "æ„Ÿå¹è¯",
            "numeral": "æ•°è¯",
            "modal": "æƒ…æ€åŠ¨è¯",
            "phrase": "çŸ­è¯­"
        }
        
        # ç»Ÿè®¡å„é˜¶æ®µçš„è¯æ€§åˆ†å¸ƒ
        for stage_name, stage_key in [("å°å­¦", "elementary"), ("åˆä¸­", "junior_high"), ("é«˜ä¸­", "high_school")]:
            print(f"     {stage_name}è¯æ€§åˆ†å¸ƒ:")
            pos_dist = stats["pos_distribution"][stage_key]
            
            # æŒ‰æ•°é‡æŽ’åº
            sorted_pos = sorted(pos_dist.items(), key=lambda x: x[1], reverse=True)
            
            # åªæ˜¾ç¤ºå‰10ä¸ªä¸»è¦è¯æ€§
            for pos, count in sorted_pos[:10]:
                pos_name = pos_mapping.get(pos, pos)
                print(f"       - {pos_name}: {count}ä¸ª")
            
            if len(sorted_pos) > 10:
                print(f"       - å…¶ä»–: {sum(count for _, count in sorted_pos[10:])}ä¸ª")
        
        # æ‰“å°æ€»è®¡è¯æ€§åˆ†å¸ƒ
        print(f"     æ€»è®¡è¯æ€§åˆ†å¸ƒ:")
        total_pos_dist = stats["pos_distribution"]["total"]
        sorted_total_pos = sorted(total_pos_dist.items(), key=lambda x: x[1], reverse=True)
        
        for pos, count in sorted_total_pos[:10]:
            pos_name = pos_mapping.get(pos, pos)
            print(f"       - {pos_name}: {count}ä¸ª")
        
        if len(sorted_total_pos) > 10:
            print(f"       - å…¶ä»–: {sum(count for _, count in sorted_total_pos[10:])}ä¸ª")
