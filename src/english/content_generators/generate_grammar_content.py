#!/usr/bin/env python3
"""
è¯­æ³•å­¦ä¹ å†…å®¹ç”Ÿæˆå™¨ï¼ˆåˆå¹¶ç‰ˆï¼‰
æ•´åˆè¯æ³•ï¼ˆMorphologyï¼‰å’Œå¥æ³•ï¼ˆSyntaxï¼‰å­¦ä¹ å†…å®¹ç”ŸæˆåŠŸèƒ½
"""

import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from src.english.content_generators.coordinate_learning_content import LearningContentGenerator


class GrammarContentGenerator:
    """è¯­æ³•å­¦ä¹ å†…å®¹ç”Ÿæˆå™¨ï¼ˆè¯æ³•+å¥æ³•ï¼‰"""
    
    def __init__(self):
        self.plan_reader = LearningContentGenerator()
        self.learning_progress = {}  # å­˜å‚¨å­¦ä¹ è¿›åº¦
        self.morphology_progress_file = Path("learning_data/english/morphology_progress.json")
        self.syntax_progress_file = Path("learning_data/english/syntax_progress.json")
        self._load_progress()
    
    def _load_progress(self):
        """åŠ è½½å­¦ä¹ è¿›åº¦"""
        # åŠ è½½è¯æ³•è¿›åº¦
        if self.morphology_progress_file.exists():
            try:
                with open(self.morphology_progress_file, 'r', encoding='utf-8') as f:
                    morphology_progress = json.load(f)
                    self.learning_progress['morphology'] = morphology_progress
            except Exception as e:
                print(f"âš ï¸ åŠ è½½è¯æ³•è¿›åº¦å¤±è´¥: {e}")
                self.learning_progress['morphology'] = {}
        else:
            self.learning_progress['morphology'] = {}
        
        # åŠ è½½å¥æ³•è¿›åº¦
        if self.syntax_progress_file.exists():
            try:
                with open(self.syntax_progress_file, 'r', encoding='utf-8') as f:
                    syntax_progress = json.load(f)
                    self.learning_progress['syntax'] = syntax_progress
            except Exception as e:
                print(f"âš ï¸ åŠ è½½å¥æ³•è¿›åº¦å¤±è´¥: {e}")
                self.learning_progress['syntax'] = {}
        else:
            self.learning_progress['syntax'] = {}
    
    def _save_progress(self):
        """ä¿å­˜å­¦ä¹ è¿›åº¦"""
        # ä¿å­˜è¯æ³•è¿›åº¦
        try:
            self.morphology_progress_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.morphology_progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.learning_progress.get('morphology', {}), f, 
                         ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¯æ³•è¿›åº¦å¤±è´¥: {e}")
        
        # ä¿å­˜å¥æ³•è¿›åº¦
        try:
            self.syntax_progress_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.syntax_progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.learning_progress.get('syntax', {}), f, 
                         ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¥æ³•è¿›åº¦å¤±è´¥: {e}")
    
    # ========== è¯æ³•ç›¸å…³åŠŸèƒ½ ==========
    
    def load_morphology_data(self, stage: str) -> Dict:
        """åŠ è½½è¯æ³•æ•°æ®"""
        # æ ¹æ®é˜¶æ®µç¡®å®šéœ€è¦åŠ è½½çš„è¯æ³•æ–‡ä»¶
        sources = self.plan_reader.get_vocab_sources({'metadata': {'stage': stage}})
        morphology_files = sources.get('morphology_files', [])
        
        morphology_data = {}
        for file_path in morphology_files:
            full_path = Path("src/english/config") / file_path
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # è§£æè¯æ³•æ•°æ®ç»“æ„
                        for key, value in data.items():
                            if isinstance(value, dict) and 'parts_of_speech' in value:
                                morphology_data[key] = value['parts_of_speech']
                except Exception as e:
                    print(f"âš ï¸ åŠ è½½è¯æ³•æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return morphology_data
    
    def generate_morphology_content(self, plan_data: Dict, day: int) -> Dict:
        """ç”Ÿæˆè¯æ³•å­¦ä¹ å†…å®¹"""
        stage = plan_data.get('metadata', {}).get('stage', 'beginner')
        morphology_data = self.load_morphology_data(stage)
        
        # è·å–å½“å¤©çš„è¯æ³•é‡ç‚¹
        daily_focus = self._get_daily_morphology_focus(plan_data, day)
        
        content = {
            "day": day,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "type": "morphology",
            "stage": stage,
            "focus": daily_focus,
            "content": {}
        }
        
        # æ ¹æ®é‡ç‚¹ç”Ÿæˆå…·ä½“å†…å®¹
        for focus_item in daily_focus:
            if focus_item in morphology_data:
                pos_data = morphology_data[focus_item]
                content["content"][focus_item] = {
                    "definition": pos_data.get("definition", ""),
                    "examples": pos_data.get("examples", [])[:3],
                    "rules": pos_data.get("rules", [])[:2],
                    "exercises": self._generate_morphology_exercises(focus_item, pos_data)
                }
        
        return content
    
    def _get_daily_morphology_focus(self, plan_data: Dict, day: int) -> List[str]:
        """è·å–å½“å¤©è¯æ³•å­¦ä¹ é‡ç‚¹"""
        morphology_plan = plan_data.get('morphology_plan', {})
        daily_topics = morphology_plan.get('daily_topics', [])
        
        if day <= len(daily_topics):
            return daily_topics[day - 1].get('topics', [])
        else:
            # å¦‚æœè¶…å‡ºè®¡åˆ’å¤©æ•°ï¼Œå¾ªç¯ä½¿ç”¨
            cycle_day = (day - 1) % len(daily_topics) if daily_topics else 0
            return daily_topics[cycle_day].get('topics', []) if daily_topics else []
    
    def _generate_morphology_exercises(self, pos_type: str, pos_data: Dict) -> List[Dict]:
        """ç”Ÿæˆè¯æ³•ç»ƒä¹ é¢˜"""
        exercises = []
        
        # è¯†åˆ«ç»ƒä¹ 
        if pos_data.get("examples"):
            exercises.append({
                "type": "identification",
                "question": f"æ‰¾å‡ºä¸‹åˆ—å¥å­ä¸­çš„{pos_data.get('definition', pos_type)}ï¼š",
                "sentence": pos_data["examples"][0] if pos_data["examples"] else "",
                "answer_type": "selection"
            })
        
        # åº”ç”¨ç»ƒä¹ 
        if pos_data.get("rules"):
            exercises.append({
                "type": "application",
                "question": f"æ ¹æ®{pos_type}çš„è§„åˆ™ï¼Œå®Œæˆä¸‹åˆ—å¥å­ï¼š",
                "rule": pos_data["rules"][0] if pos_data["rules"] else "",
                "answer_type": "fill_blank"
            })
        
        return exercises
    
    # ========== å¥æ³•ç›¸å…³åŠŸèƒ½ ==========
    
    def load_syntax_data(self, stage: str) -> Dict:
        """åŠ è½½å¥æ³•æ•°æ®"""
        # æ ¹æ®é˜¶æ®µç¡®å®šéœ€è¦åŠ è½½çš„å¥æ³•æ–‡ä»¶
        sources = self.plan_reader.get_vocab_sources({'metadata': {'stage': stage}})
        syntax_files = sources.get('syntax_files', [])
        
        syntax_data = {}
        for file_path in syntax_files:
            full_path = Path("src/english/config") / file_path
            if full_path.exists():
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # è§£æå¥æ³•æ•°æ®ç»“æ„
                        for key, value in data.items():
                            if isinstance(value, dict) and 'sentence_structures' in value:
                                syntax_data[key] = value['sentence_structures']
                except Exception as e:
                    print(f"âš ï¸ åŠ è½½å¥æ³•æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return syntax_data
    
    def generate_syntax_content(self, plan_data: Dict, day: int) -> Dict:
        """ç”Ÿæˆå¥æ³•å­¦ä¹ å†…å®¹"""
        stage = plan_data.get('metadata', {}).get('stage', 'beginner')
        syntax_data = self.load_syntax_data(stage)
        
        # è·å–å½“å¤©çš„å¥æ³•é‡ç‚¹
        daily_focus = self._get_daily_syntax_focus(plan_data, day)
        
        content = {
            "day": day,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "type": "syntax",
            "stage": stage,
            "focus": daily_focus,
            "content": {}
        }
        
        # æ ¹æ®é‡ç‚¹ç”Ÿæˆå…·ä½“å†…å®¹
        for focus_item in daily_focus:
            if focus_item in syntax_data:
                structure_data = syntax_data[focus_item]
                content["content"][focus_item] = {
                    "pattern": structure_data.get("pattern", ""),
                    "description": structure_data.get("description", ""),
                    "examples": structure_data.get("examples", [])[:3],
                    "exercises": self._generate_syntax_exercises(focus_item, structure_data)
                }
        
        return content
    
    def _get_daily_syntax_focus(self, plan_data: Dict, day: int) -> List[str]:
        """è·å–å½“å¤©å¥æ³•å­¦ä¹ é‡ç‚¹"""
        syntax_plan = plan_data.get('syntax_plan', {})
        daily_topics = syntax_plan.get('daily_topics', [])
        
        if day <= len(daily_topics):
            return daily_topics[day - 1].get('topics', [])
        else:
            # å¦‚æœè¶…å‡ºè®¡åˆ’å¤©æ•°ï¼Œå¾ªç¯ä½¿ç”¨
            cycle_day = (day - 1) % len(daily_topics) if daily_topics else 0
            return daily_topics[cycle_day].get('topics', []) if daily_topics else []
    
    def _generate_syntax_exercises(self, structure_type: str, structure_data: Dict) -> List[Dict]:
        """ç”Ÿæˆå¥æ³•ç»ƒä¹ é¢˜"""
        exercises = []
        
        # ç»“æ„è¯†åˆ«ç»ƒä¹ 
        if structure_data.get("examples"):
            exercises.append({
                "type": "structure_identification",
                "question": f"è¯†åˆ«ä¸‹åˆ—å¥å­çš„{structure_type}ç»“æ„ï¼š",
                "sentence": structure_data["examples"][0] if structure_data["examples"] else "",
                "pattern": structure_data.get("pattern", ""),
                "answer_type": "analysis"
            })
        
        # å¥å­æ„é€ ç»ƒä¹ 
        if structure_data.get("pattern"):
            exercises.append({
                "type": "sentence_construction",
                "question": f"æ ¹æ®{structure_type}çš„æ¨¡å¼æ„é€ å¥å­ï¼š",
                "pattern": structure_data["pattern"],
                "answer_type": "construction"
            })
        
        return exercises
    
    # ========== ç»¼åˆåŠŸèƒ½ ==========
    
    def generate_combined_grammar_content(self, plan_data: Dict, day: int) -> Dict:
        """ç”Ÿæˆç»¼åˆè¯­æ³•å†…å®¹ï¼ˆè¯æ³•+å¥æ³•ï¼‰"""
        morphology_content = self.generate_morphology_content(plan_data, day)
        syntax_content = self.generate_syntax_content(plan_data, day)
        
        combined_content = {
            "day": day,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "type": "combined_grammar",
            "stage": plan_data.get('metadata', {}).get('stage', 'beginner'),
            "morphology": morphology_content,
            "syntax": syntax_content,
            "integration_exercises": self._generate_integration_exercises(
                morphology_content, syntax_content
            )
        }
        
        return combined_content
    
    def _generate_integration_exercises(self, morphology_content: Dict, syntax_content: Dict) -> List[Dict]:
        """ç”Ÿæˆè¯æ³•å¥æ³•ç»¼åˆç»ƒä¹ """
        exercises = []
        
        # ç»¼åˆåˆ†æç»ƒä¹ 
        exercises.append({
            "type": "comprehensive_analysis",
            "question": "åˆ†æä¸‹åˆ—å¥å­çš„è¯æ³•å’Œå¥æ³•ç‰¹å¾ï¼š",
            "instruction": "è¯·è¯†åˆ«å¥å­ä¸­çš„è¯æ€§åˆ†å¸ƒå’Œå¥æ³•ç»“æ„",
            "answer_type": "comprehensive"
        })
        
        # ç»¼åˆæ„é€ ç»ƒä¹ 
        exercises.append({
            "type": "comprehensive_construction",
            "question": "è¿ç”¨ä»Šå¤©å­¦ä¹ çš„è¯æ³•å’Œå¥æ³•çŸ¥è¯†æ„é€ å¥å­ï¼š",
            "requirements": {
                "morphology": morphology_content.get("focus", []),
                "syntax": syntax_content.get("focus", [])
            },
            "answer_type": "construction"
        })
        
        return exercises
    
    def save_daily_progress(self, day: int, content_type: str, progress_data: Dict):
        """ä¿å­˜æ¯æ—¥å­¦ä¹ è¿›åº¦"""
        date_key = datetime.now().strftime("%Y-%m-%d")
        
        if content_type not in self.learning_progress:
            self.learning_progress[content_type] = {}
        
        self.learning_progress[content_type][date_key] = {
            "day": day,
            "completed": True,
            "timestamp": datetime.now().isoformat(),
            "progress": progress_data
        }
        
        self._save_progress()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    generator = GrammarContentGenerator()
    
    # ç¤ºä¾‹ä½¿ç”¨
    sample_plan = {
        "metadata": {"stage": "intermediate"},
        "morphology_plan": {
            "daily_topics": [
                {"topics": ["noun", "adjective"]},
                {"topics": ["verb", "adverb"]},
                {"topics": ["preposition", "conjunction"]}
            ]
        },
        "syntax_plan": {
            "daily_topics": [
                {"topics": ["simple_sentence", "compound_sentence"]},
                {"topics": ["complex_sentence", "compound_complex_sentence"]},
                {"topics": ["passive_voice", "conditional_sentences"]}
            ]
        }
    }
    
    print("ğŸ¯ è¯­æ³•å­¦ä¹ å†…å®¹ç”Ÿæˆå™¨")
    print("=" * 50)
    
    day = 1
    
    # ç”Ÿæˆè¯æ³•å†…å®¹
    print(f"\nğŸ“– ç¬¬{day}å¤©è¯æ³•å†…å®¹ï¼š")
    morphology_content = generator.generate_morphology_content(sample_plan, day)
    print(json.dumps(morphology_content, ensure_ascii=False, indent=2))
    
    # ç”Ÿæˆå¥æ³•å†…å®¹
    print(f"\nğŸ“ ç¬¬{day}å¤©å¥æ³•å†…å®¹ï¼š")
    syntax_content = generator.generate_syntax_content(sample_plan, day)
    print(json.dumps(syntax_content, ensure_ascii=False, indent=2))
    
    # ç”Ÿæˆç»¼åˆå†…å®¹
    print(f"\nğŸ”„ ç¬¬{day}å¤©ç»¼åˆè¯­æ³•å†…å®¹ï¼š")
    combined_content = generator.generate_combined_grammar_content(sample_plan, day)
    print(json.dumps(combined_content, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
