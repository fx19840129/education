#!/usr/bin/env python3
"""
ç»ƒä¹ å¥å­ç”Ÿæˆå™¨
æ ¹æ®å­¦ä¹ è®¡åˆ’ç”Ÿæˆç»ƒä¹ å¥å­
"""

import json
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from src.english.content_generators.coordinate_learning_content import LearningContentGenerator
from src.english.services.fsrs_learning_service import FSRSLearningGenerator
from src.english.services.word_morphology_service import MorphologyService
from src.english.services.sentence_syntax_service import SyntaxService
from src.english.utils.ai_prompt_builder import EnglishLearningPromptGenerator
from src.shared.ai_framework.unified_ai_client import UnifiedAIClient, AIModel


class PracticeSentencesGenerator:
    """ç»ƒä¹ å¥å­ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.plan_reader = LearningContentGenerator()
        self.fsrs_service = FSRSLearningGenerator()
        self.morphology_service = MorphologyService()
        self.syntax_service = SyntaxService()
        self.prompt_generator = EnglishLearningPromptGenerator()
        self.ai_client = UnifiedAIClient(default_model=AIModel.GLM_45)
    
    def generate_daily_sentences(self, learning_plan: Dict, target_date: str = None, vocabulary_content: Dict = None) -> Dict:
        """ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„ç»ƒä¹ å¥å­"""
        if target_date is None:
            target_date = datetime.now().strftime("%Y-%m-%d")
        
        stage = learning_plan.get("metadata", {}).get("stage", "")
        
        # ä»è¯æ±‡å†…å®¹ä¸­æå–æ–°å­¦è¯æ±‡å’Œå¤ä¹ è¯æ±‡
        new_words_data = {}
        review_words = []
        
        if vocabulary_content and 'vocabulary' in vocabulary_content:
            vocab = vocabulary_content['vocabulary']
            
            # æå–æ–°å­¦è¯æ±‡
            new_words_categories = vocab.get('new_words', {})
            all_new_words = []
            
            for category, words_list in new_words_categories.items():
                for word_data in words_list:
                    all_new_words.append({
                        'word': word_data.get('word', ''),
                        'translation': word_data.get('definition', ''),
                        'pos': word_data.get('part_of_speech', 'unknown'),
                        'difficulty': word_data.get('difficulty_level', 'medium'),
                        'category': category
                    })
            
            # æŒ‰è¯æ€§åˆ†ç»„æ–°å­¦è¯æ±‡
            pos_content = {}
            for word in all_new_words:
                pos = word['pos']
                if pos not in pos_content:
                    pos_content[pos] = []
                pos_content[pos].append(word)
            
            new_words_data = {
                "pos_content": pos_content
            }
            
            # æå–å¤ä¹ è¯æ±‡
            review_words = vocab.get('review_words', [])
        
        # è·å–è¯æ³•å’Œå¥æ³•å†…å®¹
        morphology_points = self.morphology_service.get_morphology_points(stage)
        syntax_points = self.syntax_service.get_syntax_points(stage)
        
        # è½¬æ¢ä¸ºæ‰€éœ€æ ¼å¼
        daily_morphology = {
            "morphology_items": [
                {
                    "name": point.name,
                    "type": point.category,
                    "description": point.description,
                    "rules": point.examples[:3] if point.examples else []
                }
                for point in morphology_points[:2]  # åªå–å‰2ä¸ª
            ]
        }
        
        daily_syntax = {
            "syntax_items": [
                {
                    "name": point.name,
                    "type": point.category,
                    "structure": f"{point.name} - {point.description}",
                    "examples": point.examples[:2] if point.examples else []
                }
                for point in syntax_points[:2]  # åªå–å‰2ä¸ª
            ]
        }
        
        # ç”ŸæˆAIæç¤ºè¯
        prompt = self.prompt_generator.generate_practice_sentences_prompt(
            new_words_data, daily_morphology, daily_syntax, stage, review_words
        )
        
        # è°ƒç”¨AIç”Ÿæˆç»ƒä¹ å¥å­
        try:
            ai_response = self.ai_client.generate_content(prompt)
            # æ£€æŸ¥å“åº”ç±»å‹
            if hasattr(ai_response, 'content'):
                response_text = ai_response.content
            else:
                response_text = str(ai_response)
            
            practice_data = self._parse_ai_response(response_text)
            practice_sentences = practice_data.get('practice_sentences', [])
        except Exception as e:
            print(f"âš ï¸ AIç”Ÿæˆç»ƒä¹ å¥å­å¤±è´¥: {e}")
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ç”Ÿæˆç®€å•å¥å­
            practice_sentences = self._generate_fallback_sentences(daily_words, stage)
        
        return {
            "date": target_date,
            "stage": stage,
            "total_sentences": len(practice_sentences),
            "practice_sentences": practice_sentences,
            "source": "ai_generated" if practice_sentences else "fallback"
        }
    
    def _parse_ai_response(self, ai_response: str) -> Dict:
        """è§£æAIå“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            return json.loads(ai_response)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                print(f"âš ï¸ æ— æ³•è§£æAIå“åº”: {ai_response[:200]}...")
                return {"practice_sentences": []}
    
    def _generate_fallback_sentences(self, daily_words: Dict, stage: str) -> List[Dict]:
        """å¤‡ç”¨æ–¹æ³•ï¼šç”Ÿæˆç®€å•ç»ƒä¹ å¥å­"""
        sentences = []
        
        # æ”¶é›†æ‰€æœ‰å•è¯
        all_words = []
        for pos, words in daily_words.get('pos_content', {}).items():
            for word in words:
                all_words.append({
                    'word': word['word'],
                    'pos': pos,
                    'translation': word.get('translation', ''),
                    'difficulty': word.get('difficulty', 3.0)
                })
        
        # ä¸ºæ¯ä¸ªå•è¯ç”Ÿæˆä¸€ä¸ªç®€å•å¥å­
        for word in all_words[:8]:  # æœ€å¤š8ä¸ªå¥å­
            sentence = self._create_simple_sentence(word, stage)
            if sentence:
                sentences.append(sentence)
        
        return sentences
    
    def _create_simple_sentence(self, word: Dict, stage: str) -> Dict:
        """åˆ›å»ºç®€å•å¥å­"""
        word_text = word['word']
        pos = word['pos']
        translation = word['translation']
        
        # æ ¹æ®è¯æ€§ç”Ÿæˆä¸åŒç±»å‹çš„å¥å­
        if pos == 'noun':
            sentence = f"I have a {word_text}."
            chinese = f"æˆ‘æœ‰ä¸€ä¸ª{translation}ã€‚"
        elif pos == 'verb':
            sentence = f"I {word_text} every day."
            chinese = f"æˆ‘æ¯å¤©{translation}ã€‚"
        elif pos == 'adjective':
            sentence = f"This is a {word_text} book."
            chinese = f"è¿™æ˜¯ä¸€æœ¬{translation}çš„ä¹¦ã€‚"
        elif pos == 'adverb':
            sentence = f"She runs {word_text}."
            chinese = f"å¥¹{translation}åœ°è·‘æ­¥ã€‚"
        else:
            sentence = f"I use {word_text} in my work."
            chinese = f"æˆ‘åœ¨å·¥ä½œä¸­ä½¿ç”¨{translation}ã€‚"
        
        return {
            "sentence": sentence,
            "translation": chinese,
            "target_words": [word_text],
            "morphology_points": [],
            "syntax_structure": "ç®€å•å¥",
            "difficulty": word['difficulty'],
            "exercise_type": "translation",
            "explanation": f"ç»ƒä¹ {pos}çš„ç”¨æ³•"
        }
    
    def _generate_sentences_from_words(self, daily_words: Dict, stage: str) -> List[Dict]:
        """æ ¹æ®å•è¯ç”Ÿæˆç»ƒä¹ å¥å­"""
        sentences = []
        
        # æ”¶é›†æ‰€æœ‰å•è¯
        all_words = []
        for pos, words in daily_words.get('pos_content', {}).items():
            for word in words:
                all_words.append({
                    'word': word['word'],
                    'pos': pos,
                    'difficulty': word['difficulty']
                })
        
        # æŒ‰è¯æ€§åˆ†ç»„ç”Ÿæˆå¥å­
        pos_groups = {}
        for word in all_words:
            pos = word['pos']
            if pos not in pos_groups:
                pos_groups[pos] = []
            pos_groups[pos].append(word)
        
        # ä¸ºæ¯ä¸ªè¯æ€§ç”Ÿæˆç»ƒä¹ å¥å­
        for pos, words in pos_groups.items():
            if words:
                pos_sentences = self._generate_pos_sentences(pos, words, stage)
                sentences.extend(pos_sentences)
        
        return sentences
    
    def _generate_pos_sentences(self, pos: str, words: List[Dict], stage: str) -> List[Dict]:
        """ä¸ºç‰¹å®šè¯æ€§ç”Ÿæˆç»ƒä¹ å¥å­"""
        sentences = []
        
        # æ ¹æ®è¯æ€§ç”Ÿæˆä¸åŒç±»å‹çš„å¥å­
        if pos == 'noun':
            sentences.extend(self._generate_noun_sentences(words, stage))
        elif pos == 'verb':
            sentences.extend(self._generate_verb_sentences(words, stage))
        elif pos == 'adjective':
            sentences.extend(self._generate_adjective_sentences(words, stage))
        elif pos == 'adverb':
            sentences.extend(self._generate_adverb_sentences(words, stage))
        else:
            sentences.extend(self._generate_general_sentences(pos, words, stage))
        
        return sentences
    
    def _generate_noun_sentences(self, words: List[Dict], stage: str) -> List[Dict]:
        """ç”Ÿæˆåè¯ç»ƒä¹ å¥å­"""
        sentences = []
        
        for word in words[:3]:  # æ¯ä¸ªè¯æ€§æœ€å¤š3ä¸ªå¥å­
            sentence_templates = [
                f"I have a {word['word']}.",
                f"The {word['word']} is beautiful.",
                f"This is my {word['word']}.",
                f"I like the {word['word']}.",
                f"Where is the {word['word']}?"
            ]
            
            sentence = {
                "sentence": sentence_templates[0],
                "target_word": word['word'],
                "pos": word['pos'],
                "difficulty": word['difficulty'],
                "translation": f"æˆ‘æœ‰ä¸€ä¸ª{word['word']}ã€‚",
                "exercise_type": "translation"
            }
            sentences.append(sentence)
        
        return sentences
    
    def _generate_verb_sentences(self, words: List[Dict], stage: str) -> List[Dict]:
        """ç”ŸæˆåŠ¨è¯ç»ƒä¹ å¥å­"""
        sentences = []
        
        for word in words[:3]:
            sentence_templates = [
                f"I {word['word']} every day.",
                f"She {word['word']}s well.",
                f"We can {word['word']} together.",
                f"Please {word['word']} this.",
                f"I will {word['word']} tomorrow."
            ]
            
            sentence = {
                "sentence": sentence_templates[0],
                "target_word": word['word'],
                "pos": word['pos'],
                "difficulty": word['difficulty'],
                "translation": f"æˆ‘æ¯å¤©{word['word']}ã€‚",
                "exercise_type": "translation"
            }
            sentences.append(sentence)
        
        return sentences
    
    def _generate_adjective_sentences(self, words: List[Dict], stage: str) -> List[Dict]:
        """ç”Ÿæˆå½¢å®¹è¯ç»ƒä¹ å¥å­"""
        sentences = []
        
        for word in words[:3]:
            sentence_templates = [
                f"This is a {word['word']} book.",
                f"The weather is {word['word']} today.",
                f"She looks {word['word']}.",
                f"I feel {word['word']}.",
                f"That's very {word['word']}."
            ]
            
            sentence = {
                "sentence": sentence_templates[0],
                "target_word": word['word'],
                "pos": word['pos'],
                "difficulty": word['difficulty'],
                "translation": f"è¿™æ˜¯ä¸€æœ¬{word['word']}çš„ä¹¦ã€‚",
                "exercise_type": "translation"
            }
            sentences.append(sentence)
        
        return sentences
    
    def _generate_adverb_sentences(self, words: List[Dict], stage: str) -> List[Dict]:
        """ç”Ÿæˆå‰¯è¯ç»ƒä¹ å¥å­"""
        sentences = []
        
        for word in words[:3]:
            sentence_templates = [
                f"She runs {word['word']}.",
                f"I work {word['word']}.",
                f"He speaks {word['word']}.",
                f"We study {word['word']}.",
                f"They play {word['word']}."
            ]
            
            sentence = {
                "sentence": sentence_templates[0],
                "target_word": word['word'],
                "pos": word['pos'],
                "difficulty": word['difficulty'],
                "translation": f"å¥¹{word['word']}åœ°è·‘æ­¥ã€‚",
                "exercise_type": "translation"
            }
            sentences.append(sentence)
        
        return sentences
    
    def _generate_general_sentences(self, pos: str, words: List[Dict], stage: str) -> List[Dict]:
        """ç”Ÿæˆé€šç”¨ç»ƒä¹ å¥å­"""
        sentences = []
        
        for word in words[:2]:  # å…¶ä»–è¯æ€§æœ€å¤š2ä¸ªå¥å­
            sentence_templates = [
                f"I use {word['word']} in my work.",
                f"This is about {word['word']}.",
                f"We need {word['word']} here.",
                f"Can you find {word['word']}?",
                f"I know {word['word']} well."
            ]
            
            sentence = {
                "sentence": sentence_templates[0],
                "target_word": word['word'],
                "pos": word['pos'],
                "difficulty": word['difficulty'],
                "translation": f"æˆ‘åœ¨å·¥ä½œä¸­ä½¿ç”¨{word['word']}ã€‚",
                "exercise_type": "translation"
            }
            sentences.append(sentence)
        
        return sentences
    
    def generate_sentences_schedule(self, learning_plan: Dict, days: int = 7) -> Dict:
        """ç”Ÿæˆç»ƒä¹ å¥å­å­¦ä¹ è®¡åˆ’"""
        stage = learning_plan.get("metadata", {}).get("stage", "")
        plan_name = learning_plan.get("learning_plan", {}).get("learning_plan_name", "")
        
        start_date = datetime.now().strftime("%Y-%m-%d")
        daily_schedule = []
        
        for day in range(days):
            current_date = (datetime.strptime(start_date, "%Y-%m-%d") + timedelta(days=day)).strftime("%Y-%m-%d")
            daily_content = self.generate_daily_sentences(learning_plan, current_date)
            daily_schedule.append(daily_content)
        
        return {
            "plan_name": plan_name,
            "stage": stage,
            "start_date": start_date,
            "days": days,
            "daily_schedule": daily_schedule
        }
    
    def display_sentences_content(self, schedule: Dict) -> None:
        """æ˜¾ç¤ºç»ƒä¹ å¥å­å†…å®¹"""
        if not schedule:
            print("âŒ æ²¡æœ‰ç»ƒä¹ å¥å­è®¡åˆ’æ•°æ®")
            return
        
        print("ğŸ“š ç»ƒä¹ å¥å­å­¦ä¹ è®¡åˆ’")
        print("=" * 80)
        print(f"è®¡åˆ’åç§°: {schedule['plan_name']}")
        print(f"å­¦ä¹ é˜¶æ®µ: {schedule['stage']}")
        print(f"å¼€å§‹æ—¥æœŸ: {schedule['start_date']}")
        print(f"ç”Ÿæˆå¤©æ•°: {schedule['days']}å¤©")
        print()
        
        for i, daily in enumerate(schedule['daily_schedule'], 1):
            print(f"ğŸ“… ç¬¬{i}å¤© - {daily['date']}")
            print(f"   æ€»å¥å­æ•°: {daily['total_sentences']}ä¸ª")
            print()
            
            if daily['practice_sentences']:
                for j, sentence in enumerate(daily['practice_sentences'], 1):
                    print(f"   ğŸ“– {j}. {sentence['sentence']}")
                    print(f"      ç¿»è¯‘: {sentence['translation']}")
                    if sentence.get('target_words'):
                        print(f"      ç›®æ ‡å•è¯: {', '.join(sentence['target_words'])}")
                    if sentence.get('morphology_points'):
                        print(f"      è¯æ³•ç‚¹: {', '.join(sentence['morphology_points'])}")
                    if sentence.get('syntax_structure'):
                        print(f"      å¥æ³•ç»“æ„: {sentence['syntax_structure']}")
                    print(f"      éš¾åº¦: {sentence['difficulty']:.1f}")
                    print(f"      ç»ƒä¹ ç±»å‹: {sentence['exercise_type']}")
                    if sentence.get('explanation'):
                        print(f"      è§£é‡Š: {sentence['explanation']}")
                    print()
            else:
                print("   ä»Šå¤©æ²¡æœ‰ç»ƒä¹ å¥å­")
            
            print("-" * 80)
            print()
    
    def generate_and_display(self, learning_plan: Dict, days: int = 7) -> None:
        """ç”Ÿæˆå¹¶æ˜¾ç¤ºç»ƒä¹ å¥å­å†…å®¹"""
        print(f"ğŸ“‹ ä½¿ç”¨å­¦ä¹ è®¡åˆ’: {learning_plan.get('id', 'æœªçŸ¥')}")
        print(f"ğŸ“‹ å­¦ä¹ é˜¶æ®µ: {learning_plan['metadata']['stage']}")
        print()
        
        # ç”Ÿæˆç»ƒä¹ å¥å­å­¦ä¹ è®¡åˆ’
        schedule = self.generate_sentences_schedule(learning_plan, days)
        
        # æ˜¾ç¤ºå­¦ä¹ å†…å®¹
        self.display_sentences_content(schedule)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        total_sentences = sum(daily['total_sentences'] for daily in schedule['daily_schedule'])
        avg_daily = total_sentences / days if days > 0 else 0
        
        print("ğŸ“Š ç»ƒä¹ å¥å­ç»Ÿè®¡:")
        print(f"   æ€»å¥å­æ•°: {total_sentences}ä¸ª")
        print(f"   å­¦ä¹ å¤©æ•°: {days}å¤©")
        print(f"   å¹³å‡æ¯å¤©: {avg_daily:.1f}ä¸ªå¥å­")
        print()


def main():
    """ä¸»å‡½æ•°"""
    generator = PracticeSentencesGenerator()
    plan_reader = LearningContentGenerator()
    
    print("ğŸ” ç»ƒä¹ å¥å­ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    plan_id = input("è¯·è¾“å…¥å­¦ä¹ è®¡åˆ’ID (æŒ‰å›è½¦ä½¿ç”¨æœ€æ–°è®¡åˆ’): ").strip()
    if not plan_id:
        plans = plan_reader.list_plans()
        if plans:
            plan_id = plans[0]['id']
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å­¦ä¹ è®¡åˆ’")
            return
    
    try:
        days = int(input("è¯·è¾“å…¥ç”Ÿæˆå¤©æ•° (é»˜è®¤7å¤©): ").strip() or "7")
    except ValueError:
        days = 7
    
    print()
    
    # è¯»å–å­¦ä¹ è®¡åˆ’
    learning_plan = plan_reader.read_plan(plan_id=plan_id)
    if not learning_plan:
        print(f"âŒ æ— æ³•è¯»å–å­¦ä¹ è®¡åˆ’: {plan_id}")
        return
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºç»ƒä¹ å¥å­å†…å®¹
    generator.generate_and_display(learning_plan, days)
    
    print("\nâœ… ç»ƒä¹ å¥å­ç”Ÿæˆå®Œæˆ!")


if __name__ == "__main__":
    main()
